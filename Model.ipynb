{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all the reuired libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached https://files.pythonhosted.org/packages/b5/84/ac0c239ffc4cde7c3aa9840ce734b42d4e9100e76927c6ed0100f00de10a/pyarrow-4.0.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\nisha\\anaconda3\\lib\\site-packages (from pyarrow) (1.20.3)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-4.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installing pyarrow to read parquet input files\n",
    "#pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leads= pd.read_parquet('ds_leads.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_uuid</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>apr</th>\n",
       "      <th>lender_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ae2d5046-a7c7-44fe-b6f4-cde3d8bf29e2</td>\n",
       "      <td>810117850</td>\n",
       "      <td>199.00</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>b12fbb06-1402-4de3-a91f-fb6360ff85e4</td>\n",
       "      <td>810119030</td>\n",
       "      <td>249.00</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>a119a3db-ab14-46fc-acd1-35cf20dec1ec</td>\n",
       "      <td>810122970</td>\n",
       "      <td>249.00</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3166d6bd-1c79-44c0-867c-889afd35990c</td>\n",
       "      <td>810124218</td>\n",
       "      <td>17.69</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3166d6bd-1c79-44c0-867c-889afd35990c</td>\n",
       "      <td>810124220</td>\n",
       "      <td>17.19</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lead_uuid   offer_id     apr  lender_id\n",
       "33  ae2d5046-a7c7-44fe-b6f4-cde3d8bf29e2  810117850  199.00       1103\n",
       "35  b12fbb06-1402-4de3-a91f-fb6360ff85e4  810119030  249.00       1103\n",
       "38  a119a3db-ab14-46fc-acd1-35cf20dec1ec  810122970  249.00       1103\n",
       "40  3166d6bd-1c79-44c0-867c-889afd35990c  810124218   17.69        240\n",
       "41  3166d6bd-1c79-44c0-867c-889afd35990c  810124220   17.19        240"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers= pd.read_parquet('ds_offers.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_id</th>\n",
       "      <th>clicked_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810116813</td>\n",
       "      <td>2021-03-23 02:01:48.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>810118339</td>\n",
       "      <td>2021-03-23 02:01:14.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>810132429</td>\n",
       "      <td>2021-03-23 02:46:49.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>810152009</td>\n",
       "      <td>2021-03-23 04:46:19.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>810177207</td>\n",
       "      <td>2021-03-23 08:44:04.494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    offer_id              clicked_at\n",
       "0  810116813 2021-03-23 02:01:48.339\n",
       "1  810118339 2021-03-23 02:01:14.135\n",
       "2  810132429 2021-03-23 02:46:49.753\n",
       "3  810152009 2021-03-23 04:46:19.662\n",
       "4  810177207 2021-03-23 08:44:04.494"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks= pd.read_parquet('ds_clicks.parquet.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to mysql db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mysql engine object to connect to mysql db\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost:3306/{db}\"\n",
    "                       .format(user=\"root\",\n",
    "                               pw=\"aaryan007\",\n",
    "                               db=\"even\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads.to_sql(con=engine,name='leads',if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers.to_sql(con=engine,name='offers',if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.to_sql(con=engine,name='clicks',if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from mysql db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads= pd.read_sql(\"select * from leads\", engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers= pd.read_sql(\"select * from offers\", engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clicks= pd.read_sql(\"select * from clicks\", engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Joining offers and leads dataframe\n",
    "\n",
    "offers_leads= pd.merge(offers,leads,how='left',on='lead_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for rows with null values\n",
    "offers_leads.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropped the rows with na values as the count of such rows was less than 1% so imputation are not required.\n",
    "offers_leads.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##joining offers_leads dataframe with clicks to get which offers were clicked\n",
    "\n",
    "joined_df= pd.merge(offers_leads,clicks.rename(columns={'offer_id':'offer_id_2'}),how='left',left_on='offer_id',right_on='offer_id_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Considering \"limited\" and \"Unknown\" credit means we donot have enough information to generate credit score. \n",
    "## I am creating a new column \"nocredit\" to depict such leads\n",
    "\n",
    "joined_df['nocredit']=joined_df['credit'].apply(lambda c: 1 if c in (\"limited\",'unknown') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping credit into numerical values in ordinal format.\n",
    "\n",
    "joined_df['credit_bucket']= joined_df['credit'].map({'limited':0,'unknown':0,'poor':1,'good':2,'fair':3,'excellent':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting and trqansforming one-hot encoding the loan_purpose values as it is an nominal column\n",
    "\n",
    "enc=OneHotEncoder()\n",
    "enc.fit_transform(joined_df[['loan_purpose']])\n",
    "\n",
    "import pickle\n",
    "with open(\"encoder\", \"wb\") as f: \n",
    "    pickle.dump(enc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df=pd.concat([joined_df,pd.DataFrame(enc.fit_transform(joined_df[['loan_purpose']]).toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating output column based on clicks\n",
    "\n",
    "joined_df['output']= joined_df['offer_id_2'].fillna(0).apply(lambda k: k if k==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping column irrelavent for model training and testing\n",
    "joined_df.drop(columns=['lead_uuid','offer_id','lender_id','clicked_at','offer_id_2','loan_purpose','credit'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=joined_df.drop(columns=['output'])\n",
    "y=joined_df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test set in 80% and 20% ratio.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the Logistic Regression on train set and scoring it \n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_model\",\"wb\") as f:\n",
    "    pickle.dump(clf,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
